# Evaluation Datasets

## Overview

This directory contains test dataset **templates** with placeholder syntax for sensitive business data. These templates are committed to version control.

## Directory Structure

```
eval/datasets/
├── README.md                    # This file
├── test_questions.yaml          # Template with {{PLACEHOLDER}} syntax
└── single_question_test.yaml    # Quick test with one question

eval/datasets_sensitive/         # Gitignored - hydrated files go here
└── test_questions_hydrated.yaml # Generated by hydration script
```

## Template Syntax

Use `{{PLACEHOLDER|format}}` for sensitive data that should be hydrated from database:

### Supported Formats

- `{{COLUMN_NAME|currency}}` → €1,234,567
- `{{COLUMN_NAME|percentage}}` → 45.3%
- `{{COLUMN_NAME|units}}` → 1,234 units
- `{{COLUMN_NAME|number}}` → 1,234,567

### Example Template

```yaml
- question: "What was total sales in Q3 2024?"
  expected_outcome: |
    [AGENT:sales_agent|REASON:Question asks for sales metrics]
    
    Q3 2024 total sales were {{TotalSales|currency}}. This represents
    a {{GrowthRate|percentage}} increase compared to Q3 2023.
  sql_query: |
    SELECT SUM(sales) as TotalSales,
           ((SUM(sales) - prev_q3) / prev_q3 * 100) as GrowthRate
    FROM sales_data
    WHERE quarter = 'Q3' AND year = 2024
```

## Hydration Workflow

### 1. Create Template
Edit `test_questions.yaml` with {{PLACEHOLDER}} syntax for sensitive numbers.

### 2. Run Hydration Script
```bash
# Hydrate template with real data
python eval/datasets/hydrate_test_data.py \
    --template eval/datasets/test_questions.yaml \
    --output eval/datasets_sensitive/test_questions_hydrated.yaml
```

### 3. Run Evaluation
```bash
# Use hydrated file with pyrit-eval
pyrit-eval run \
    --config eval/config.yaml \
    --dataset-path eval/datasets_sensitive/test_questions_hydrated.yaml \
    ...
```

## Security Notes

⚠️ **IMPORTANT**:
- Template files (this directory): Safe to commit ✅
- Hydrated files (datasets_sensitive/): **NEVER commit** ❌
- Hydrated files contain real business data and are automatically gitignored
- Always re-hydrate before running evaluation in a new environment

## Test Case Format

Each test case in the YAML file should have:

```yaml
- question: "User's question"
  expected_outcome: |
    [AGENT:agent_name|REASON:Why this agent is expected]
    
    Expected answer pattern with {{PLACEHOLDERS|format}} for numbers.
    Should describe what a good answer contains.
  sql_query: |
    (Optional) SQL query to fetch placeholder values
    Must return columns matching placeholder names
```

### Agent Routing Pattern

Always include `[AGENT:agent_name|REASON:explanation]` at the start of expected_outcome for routing validation:

```yaml
expected_outcome: |
  [AGENT:customer_insights|REASON:Question asks for customer metrics]
  
  The rest of the expected answer content...
```

## Example Test Questions

See `test_questions.yaml` and `single_question_test.yaml` for examples covering:
- Numerical accuracy validation
- SQL methodology checks
- Agent routing validation
- Completeness assessment
- Assumption transparency
- Error handling

## Creating New Test Cases

### Best Practices

1. **Routing**: Always specify expected agent with reasoning
2. **Numbers**: Use {{PLACEHOLDER}} for sensitive data
3. **Citations**: Mention expected data sources in outcome
4. **Assumptions**: Document expected assumptions when question is ambiguous
5. **SQL**: Include actual SQL if validating methodology

### Template Example

```yaml
- question: "How many weekly customers in Q2 2024?"
  expected_outcome: |
    [AGENT:customer_insights|REASON:Customer metrics question]
    
    Average of {{AvgWeeklyCustomers|number}} customers per week in Q2 2024
    (weeks 14-26). This is based on basis_customer_total table.
    
    Assumption: Q2 defined as weeks 14-26 of fiscal year.
  sql_query: |
    SELECT AVG(Customers) as AvgWeeklyCustomers
    FROM basis_customer_total
    WHERE WEEKNR BETWEEN 14 AND 26 AND YEAR = 2024
```

## Troubleshooting

### Hydration Issues

**Problem**: Placeholder not replaced
**Solution**: Ensure column name in {{PLACEHOLDER}} matches SQL SELECT alias

**Problem**: Hydration script fails
**Solution**: Check database connection, verify SQL query syntax

### Evaluation Issues

**Problem**: Low numerical accuracy scores
**Solution**: Ensure numbers in expected_outcome match agent's precision

**Problem**: Agent routing failing
**Solution**: Verify [AGENT:name|REASON:...] pattern syntax is correct
